# -*- coding: utf-8 -*-
"""Copy of Nuwase_tweets_sentiment_analysis_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bHl52R9zie6mNF1Dzn7VdgOzDH3ISrGI

**EMOTION DETECTION OF TWEET REPLIES TO THE RWANDA'S OFFICE OF THE PM**

This is a logistic regression model trained on a pre- processed dataset that contains tweets with their associated emotions. this model can be applied on retrieved tweet mentions of a governmental organization in Rwanda to know how the public is receiving different policy implementations/communications,etc... and get a general idea of the emotions and attitude regarding particular decisions,policies, events,etc..


For the purpose of showing how the model would be applied, I used replies to the office of the prime minister. predicted emotions on tweet replies based on the trained model and made a visualisiation of the summary of the prevalent emotions
"""

import pandas as pd
import numpy as np
import seaborn as sns

import os
import tweepy as tw

consumer_key= 'upWs4iRLt7GNdelig0uZr7OCw'
consumer_secret= 'zDbYOrPwbVERyskPG71Dz11JIDSTHvMd0olswowdim5RJOiAdM'
access_token= '918560003639971842-u3G6jdMhnO6ItaBK3Tlmu2aehPIY2RI'
access_token_secret= 'G0tUiNkIk3kiAdKk2p5rM7UIo9qxKC5kFv5x1zMiamgfS'
auth = tw.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tw.API(auth, wait_on_rate_limit=True)

#retrieving tweets mentioning one of the Rwandan government institutions twitter account, in this case i used the office of the prime minister(@PrimatureRwanda)
# since they have been giving a lot of updates, these tweets will be analysed to know the sentiment of the feedback that their communications/publications have
#been getting in view of these events

mentioned_account = "to:PrimatureRwanda -filter:retweets"
date_since = "2018-11-16"

tweets = api.user_timeline(q=mentioned_account, count= 50,
                           lang="en",
                           since=date_since)
tweets_text = [[tweet.text] for tweet in tweets]
tweets_text

#i only retrieved 50 tweets for now to not reach the limit

tweet_text = pd.DataFrame(data = tweets_text, 
                    columns=["text"])
tweet_text

import re
def tweets_cleaner(text):
  text = re.sub('@[A-Za-z0â€“9]+', '', text) #Removing @mentions
  text = re.sub('#', '', text) # Removing '#' hash tag
  text = re.sub('RT[\s]+', '', text) # Removing RT
  text = re.sub('https?:\/\/\S+', '', text) # Removing hyperlink

  return text
tweet_text['text'] = tweet_text['text'].apply(tweets_cleaner)
tweet_text

#I will now create a logistic regression prediction model based on a preprocessed tweets- emotions dataset that was created for sentiment analysis

#loading the libraries for the model development
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix

emotions_dataset = pd.read_csv("https://raw.githubusercontent.com/Jcharis/end2end-nlp-project/main/data/emotion_dataset_2.csv")
emotions_dataset

emotions_dataset.isnull().sum()

#replace the missing data with empty space
emotions_dataset.fillna('', inplace=True)

#the distribution of the data 
emotions_dataset['Emotion'].value_counts()

x_features = emotions_dataset['Clean_Text']
y_labels = emotions_dataset['Emotion']

#splitting the data in the training set and validation/testing set
x_train,x_val,y_train,y_val = train_test_split(x_features,y_labels,test_size=0.3,random_state=42)

#building the ml model pipeline
from sklearn.pipeline import Pipeline
log_regr_pl = Pipeline(steps=[('cv',CountVectorizer()),('lr',LogisticRegression())])

#fitting it to the training dataset
log_regr_pl.fit(x_train,y_train)

log_regr_pl.score(x_val,y_val)

#appling this model to the extracted tweets
tweet_text['emotions pred'] = log_regr_pl.predict(tweet_text['text'])
tweet_text

#visualising the distribution of the emotions identified in tweet replies/ feedback  that the office of the prime minister got on their recent publications

import matplotlib.pyplot as plt


plt.title('Office of the PM tweet replies emotional overview/analysis')
plt.xlabel('Emotions')
plt.ylabel('Counts')
tweet_text['emotions pred'].value_counts().plot(kind = 'bar')
plt.show()

# saving the model 
import joblib 
pipeline_file = open("tweets_emotions_classifier.pkl", mode = "wb") 
joblib.dump(log_regr_pl, pipeline_file)
pipeline_file.save("models")
pipeline_file.close()